# -*- coding: utf-8 -*-
"""CompanyNewsBot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OHAAvp1rIwrJmJRMg6qR5vjivOPYm7pc
"""

!pip install -q --upgrade \
  gradio \
  beautifulsoup4 \
  requests \
  llama-cpp-python \
  transformers \
  rapidfuzz \
  spacy[transformers] \
  newsapi-python

!python -m spacy download en_core_web_trf

import requests
from bs4 import BeautifulSoup
from transformers import pipeline
from rapidfuzz import process
import re
import spacy
from newsapi import NewsApiClient


# Pre-load summarizer
summarizer_pipeline = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")


# --- Agent Classes ---

newsapi = NewsApiClient(api_key="e638eb71e0ca480c80246549b28a58d6")

class SearchAgent:
    def get_links(self, company, num_results=3):
        articles = newsapi.get_everything(
            q=company,
            language='en',
            sort_by='publishedAt',
            page_size=num_results
        )
        return [a['url'] for a in articles['articles']]

class ScrapeAgent:
    def get_article_text(self, url):
        try:
            res = requests.get(url, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            text = ' '.join(p.get_text() for p in soup.find_all('p'))
            return text[:3000]
        except:
            return ""

class SummarizerAgent:
    def summarize(self, text, style="formal"):
      if not text.strip():
          return "No content found to summarize."

      input_len = len(text.split())
      max_len = max(20, min(130, int(input_len * 0.6)))  # 60% of input
      min_len = max(10, int(max_len * 0.5))              # half of max_len

      try:
          summary = summarizer_pipeline(
              text,
              max_length=max_len,
              min_length=min_len,
              do_sample=False
          )[0]['summary_text']
      except Exception as e:
          return f"Error during summarization: {e}"

      if style == "casual":
          return f"Hereâ€™s the gist: {summary}"
      elif style == "bullets":
          return "â€¢ " + summary.replace('. ', '.\nâ€¢ ')
      else:
          return summary

nlp = spacy.load("en_core_web_trf")  # Open-source, free

class ChatAgent:

    GENERIC_WORDS = {"news", "latest", "company", "update", "updates", "report", "headline", "business"}

    def is_company_question(self, user_input):
      keywords = ["news", "latest", "about", "update", "tell", "report", "new"]
      return any(word in user_input.lower() for word in keywords)


    def extract_companies(self, user_input):
        doc = nlp(user_input)
        candidates = set()

        # 1. Extract ORG-type entities (like Google, Meta)
        for ent in doc.ents:
            if ent.label_ == "ORG":
                candidates.add(ent.text.strip())


        return list(candidates)

# Initialize agents
search_agent = SearchAgent()
scrape_agent = ScrapeAgent()
summarizer_agent = SummarizerAgent()
chat_agent = ChatAgent()


def handle_chat(user_input, style="formal"):
    greetings = ["hi", "hello", "hey", "how are you"]
    if user_input.lower().strip() in greetings:
        return "Hi! ðŸ‘‹ I'm your news buddy. Ask me about any company!"

    if not chat_agent.is_company_question(user_input):
        return "I'm a bot to get only company latest news. Sorry, I could not answer these questions."

    companies = chat_agent.extract_companies(user_input)
    if not companies:
        return "Sorry, I couldn't recognize any valid company in your message. Try again with correct names."

    full_response = ""
    for company in companies:
        links = search_agent.get_links(company)
        if not links:
            full_response += f"ðŸ”¹ **{company}**\nNo news links found.\n\n"
            continue

        summaries = []
        additional_links = []
        for link in links:
            article = scrape_agent.get_article_text(link)
            summary = summarizer_agent.summarize(article, style)

            # If summary is valid, add it under the company section
            if "No content" in summary or "Error during summarization" in summary:
                additional_links.append(link)
            else:
                summaries.append(f"â€¢ {summary}\n[Read full article]({link})")

        # Add the summaries (if any)
        if summaries:
            full_response += f"ðŸ”¹ **{company}**\n" + "\n\n".join(summaries) + "\n\n"

        # Add "Additional links" section (if any)
        if additional_links:
            full_response += f"ðŸ“Ž **Additional links for {company}:**\n" + \
                            "\n".join(f"[Open]({link})" for link in additional_links) + "\n\n"



    return full_response.strip() or "No content could be fetched at the moment."

import gradio as gr

style_choices = ["formal", "casual", "bullets"]

gr.Interface(
    fn=handle_chat,
    inputs=[
        gr.Textbox(label="Ask about a company or just chat"),
        gr.Dropdown(choices=style_choices, label="Output Style", value="formal")
    ],
    outputs="markdown",
    title="ðŸ“° Smart Company News Bot",
    description="Ask about companies like Google, Meta, Apple. Get real-time news summaries in your selected style!"
).launch(debug=True)