{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "KHr1bUcyzcCO"
      },
      "outputs": [],
      "source": [
        "!pip install -q \\\n",
        "  gradio \\\n",
        "  googlesearch-python \\\n",
        "  beautifulsoup4 \\\n",
        "  requests \\\n",
        "  transformers \\\n",
        "  spacy[transformers]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zXrO8HNQZEUs",
        "outputId": "eabc9dc6-21cc-4fcb-cb1c-0a7f4dc8dbd6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-trf==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
            "  Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
            "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
            "  Downloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.11/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
            "Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m237.9/237.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (735 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m735.6/735.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
            "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.1\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googlesearch import search\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Pre-load summarizer\n",
        "summarizer_pipeline = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "# --- Agent Classes ---\n",
        "\n",
        "class SearchAgent:\n",
        "    def get_links(self, company, num_results=3):\n",
        "        query = f\"{company} latest news\"\n",
        "        return list(search(query, num_results=num_results))\n",
        "\n",
        "class ScrapeAgent:\n",
        "    def get_article_text(self, url):\n",
        "        try:\n",
        "            res = requests.get(url, timeout=5)\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "            text = ' '.join(p.get_text() for p in soup.find_all('p'))\n",
        "            return text[:3000]\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "class SummarizerAgent:\n",
        "    def summarize(self, text, style=\"formal\"):\n",
        "      if not text.strip():\n",
        "          return \"No content found to summarize.\"\n",
        "\n",
        "      input_len = len(text.split())\n",
        "      max_len = max(20, min(130, int(input_len * 0.6)))  # 60% of input\n",
        "      min_len = max(10, int(max_len * 0.5))              # half of max_len\n",
        "\n",
        "      try:\n",
        "          summary = summarizer_pipeline(\n",
        "              text,\n",
        "              max_length=max_len,\n",
        "              min_length=min_len,\n",
        "              do_sample=False\n",
        "          )[0]['summary_text']\n",
        "      except Exception as e:\n",
        "          return f\"Error during summarization: {e}\"\n",
        "\n",
        "      if style == \"casual\":\n",
        "          return f\"Hereâ€™s the gist: {summary}\"\n",
        "      elif style == \"bullets\":\n",
        "          return \"â€¢ \" + summary.replace('. ', '.\\nâ€¢ ')\n",
        "      else:\n",
        "          return summary\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_trf\")  # Open-source, free\n",
        "\n",
        "class ChatAgent:\n",
        "\n",
        "    GENERIC_WORDS = {\"news\", \"latest\", \"company\", \"update\", \"updates\", \"report\", \"headline\", \"business\"}\n",
        "\n",
        "    def is_company_question(self, user_input):\n",
        "      keywords = [\"news\", \"latest\", \"about\", \"update\", \"tell\", \"report\", \"new\"]\n",
        "      return any(word in user_input.lower() for word in keywords)\n",
        "\n",
        "\n",
        "    def extract_companies(self, user_input):\n",
        "        doc = nlp(user_input)\n",
        "        candidates = set()\n",
        "\n",
        "        # 1. Extract ORG-type entities (like Google, Meta)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"ORG\":\n",
        "                candidates.add(ent.text.strip())\n",
        "\n",
        "        return list(candidates)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q78d98yC1CTl",
        "outputId": "480deb1a-26d8-4315-8c48-7929f7cd51a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize agents\n",
        "search_agent = SearchAgent()\n",
        "scrape_agent = ScrapeAgent()\n",
        "summarizer_agent = SummarizerAgent()\n",
        "chat_agent = ChatAgent()\n",
        "\n",
        "\n",
        "def handle_chat(user_input, style=\"formal\"):\n",
        "    greetings = [\"hi\", \"hello\", \"hey\", \"how are you\"]\n",
        "    if user_input.lower().strip() in greetings:\n",
        "        return \"Hi! ğŸ‘‹ I'm your news buddy. Ask me about any company!\"\n",
        "\n",
        "    if not chat_agent.is_company_question(user_input):\n",
        "        return \"I'm a bot to get only company latest news. Sorry, I could not answer these questions.\"\n",
        "\n",
        "    companies = chat_agent.extract_companies(user_input)\n",
        "    if not companies:\n",
        "        return \"Sorry, I couldn't recognize any valid company in your message. Try again with correct names.\"\n",
        "\n",
        "    full_response = \"\"\n",
        "    for company in companies:\n",
        "        links = search_agent.get_links(company)\n",
        "        if not links:\n",
        "            full_response += f\"ğŸ”¹ **{company}**\\nNo news links found.\\n\\n\"\n",
        "            continue\n",
        "\n",
        "        summaries = []\n",
        "        additional_links = []\n",
        "        for link in links:\n",
        "            article = scrape_agent.get_article_text(link)\n",
        "            summary = summarizer_agent.summarize(article, style)\n",
        "\n",
        "            # If summary is valid, add it under the company section\n",
        "            if \"No content\" in summary or \"Error during summarization\" in summary:\n",
        "                additional_links.append(link)\n",
        "            else:\n",
        "                summaries.append(f\"â€¢ {summary}\\n[Read full article]({link})\")\n",
        "\n",
        "        # Add the summaries (if any)\n",
        "        if summaries:\n",
        "            full_response += f\"ğŸ”¹ **{company}**\\n\" + \"\\n\\n\".join(summaries) + \"\\n\\n\"\n",
        "\n",
        "        # Add \"Additional links\" section (if any)\n",
        "        if additional_links:\n",
        "            full_response += f\"ğŸ“ **Additional links for {company}:**\\n\" + \\\n",
        "                            \"\\n\".join(f\"[Open]({link})\" for link in additional_links) + \"\\n\\n\"\n",
        "\n",
        "\n",
        "\n",
        "    return full_response.strip() or \"No content could be fetched at the moment.\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4PCN3gVK5wcA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "style_choices = [\"formal\", \"casual\", \"bullets\"]\n",
        "\n",
        "gr.Interface(\n",
        "    fn=handle_chat,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ask about a company or just chat\"),\n",
        "        gr.Dropdown(choices=style_choices, label=\"Output Style\", value=\"formal\")\n",
        "    ],\n",
        "    outputs=\"markdown\",\n",
        "    title=\"ğŸ“° Smart Company News Bot\",\n",
        "    description=\"Ask about companies like Google, Meta, Apple. Get real-time news summaries in your selected style!\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "lv2T5Zj_58B3",
        "outputId": "645c210a-722d-4dce-bb1a-0538bc05a405"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://60af52dab79ad2a703.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://60af52dab79ad2a703.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}